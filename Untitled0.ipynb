{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalar bibliotecas necessárias\n",
        "!pip -q install nltk spacy && python -m spacy download pt_core_news_sm\n",
        "\n",
        "# Importar bibliotecas\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import ngrams\n",
        "\n",
        "# Baixar stopwords do NLTK\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Carregar modelo de português do spaCy\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "# Corpus fornecido (com aspas corrigidas)\n",
        "text = (\n",
        "    \"A Sra. Rosa plantou uma rosa no jardim. O céu estava azul e a brisa era suave. \"\n",
        "    \"Ela pensou: \\\"Seria maravilhoso se todos os dias fossem assim, tão tranquilos quanto uma rosa em flor.\\\"\"\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Tokenização (com pontuação e maiúsculas)\n",
        "tokens = re.findall(r'\\w+', text)\n",
        "print(\"Tokens (com pontuação e maiúsculas):\")\n",
        "print(tokens)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Normalização (remover pontuação e converter para minúsculas)\n",
        "tokens_norm = re.findall(r'\\w+', text.lower())\n",
        "print(\"\\nTokens normalizados:\")\n",
        "print(tokens_norm)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Remoção de Stop Words\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "filtered_tokens = [word for word in tokens_norm if word not in stop_words]\n",
        "print(\"\\nTokens sem stopwords:\")\n",
        "print(filtered_tokens)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Geração de n-gramas\n",
        "unigrams = list(ngrams(filtered_tokens, 1))\n",
        "bigrams = list(ngrams(filtered_tokens, 2))\n",
        "trigrams = list(ngrams(filtered_tokens, 3))\n",
        "\n",
        "print(\"\\nUnigramas:\")\n",
        "print(unigrams)\n",
        "print(\"\\nBigramas:\")\n",
        "print(bigrams)\n",
        "print(\"\\nTrigramas:\")\n",
        "print(trigrams)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Lematização com spaCy\n",
        "doc = nlp(\" \".join(filtered_tokens))\n",
        "lemmatized = [token.lemma_ for token in doc]\n",
        "print(\"\\nTokens lematizados:\")\n",
        "print(lemmatized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CafBuNQwGtW_",
        "outputId": "957e2d47-b9ac-4d28-c63a-b9b1b3f080b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens (com pontuação e maiúsculas):\n",
            "['A', 'Sra', 'Rosa', 'plantou', 'uma', 'rosa', 'no', 'jardim', 'O', 'céu', 'estava', 'azul', 'e', 'a', 'brisa', 'era', 'suave', 'Ela', 'pensou', 'Seria', 'maravilhoso', 'se', 'todos', 'os', 'dias', 'fossem', 'assim', 'tão', 'tranquilos', 'quanto', 'uma', 'rosa', 'em', 'flor']\n",
            "\n",
            "Tokens normalizados:\n",
            "['a', 'sra', 'rosa', 'plantou', 'uma', 'rosa', 'no', 'jardim', 'o', 'céu', 'estava', 'azul', 'e', 'a', 'brisa', 'era', 'suave', 'ela', 'pensou', 'seria', 'maravilhoso', 'se', 'todos', 'os', 'dias', 'fossem', 'assim', 'tão', 'tranquilos', 'quanto', 'uma', 'rosa', 'em', 'flor']\n",
            "\n",
            "Tokens sem stopwords:\n",
            "['sra', 'rosa', 'plantou', 'rosa', 'jardim', 'céu', 'azul', 'brisa', 'suave', 'pensou', 'maravilhoso', 'todos', 'dias', 'assim', 'tão', 'tranquilos', 'quanto', 'rosa', 'flor']\n",
            "\n",
            "Unigramas:\n",
            "[('sra',), ('rosa',), ('plantou',), ('rosa',), ('jardim',), ('céu',), ('azul',), ('brisa',), ('suave',), ('pensou',), ('maravilhoso',), ('todos',), ('dias',), ('assim',), ('tão',), ('tranquilos',), ('quanto',), ('rosa',), ('flor',)]\n",
            "\n",
            "Bigramas:\n",
            "[('sra', 'rosa'), ('rosa', 'plantou'), ('plantou', 'rosa'), ('rosa', 'jardim'), ('jardim', 'céu'), ('céu', 'azul'), ('azul', 'brisa'), ('brisa', 'suave'), ('suave', 'pensou'), ('pensou', 'maravilhoso'), ('maravilhoso', 'todos'), ('todos', 'dias'), ('dias', 'assim'), ('assim', 'tão'), ('tão', 'tranquilos'), ('tranquilos', 'quanto'), ('quanto', 'rosa'), ('rosa', 'flor')]\n",
            "\n",
            "Trigramas:\n",
            "[('sra', 'rosa', 'plantou'), ('rosa', 'plantou', 'rosa'), ('plantou', 'rosa', 'jardim'), ('rosa', 'jardim', 'céu'), ('jardim', 'céu', 'azul'), ('céu', 'azul', 'brisa'), ('azul', 'brisa', 'suave'), ('brisa', 'suave', 'pensou'), ('suave', 'pensou', 'maravilhoso'), ('pensou', 'maravilhoso', 'todos'), ('maravilhoso', 'todos', 'dias'), ('todos', 'dias', 'assim'), ('dias', 'assim', 'tão'), ('assim', 'tão', 'tranquilos'), ('tão', 'tranquilos', 'quanto'), ('tranquilos', 'quanto', 'rosa'), ('quanto', 'rosa', 'flor')]\n",
            "\n",
            "Tokens lematizados:\n",
            "['Sra', 'Rosa', 'plantar', 'roso', 'Jardim', 'céu', 'azul', 'brisa', 'suave', 'pensar', 'maravilhoso', 'todo', 'dia', 'assim', 'tão', 'tranquilo', 'quanto', 'rosar', 'flor']\n"
          ]
        }
      ]
    }
  ]
}